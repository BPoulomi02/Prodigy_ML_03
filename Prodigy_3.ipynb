{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7J-kZj3G5S9",
        "outputId": "4bf84a39-8ac3-490b-e027-0f9cae4885df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import the libraries"
      ],
      "metadata": {
        "id": "aM2lqak0KAf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "SEWunLhsJLzJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load and Preprocess the Training Data"
      ],
      "metadata": {
        "id": "jne6_Sz2JbGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/Prodigy_3/train'"
      ],
      "metadata": {
        "id": "3hFxPmmoJvbY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "train_images = []\n",
        "train_labels = []\n",
        "\n",
        "for filename in os.listdir(train_path):\n",
        "    img_path = os.path.join(train_path, filename)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (64, 64))  # Resize images to 64x64\n",
        "    img = img.flatten()\n",
        "\n",
        "\n",
        "    if \"cat\" in filename:\n",
        "        label = 1  # 1 for cats\n",
        "    elif \"dog\" in filename:\n",
        "        label = 0  # 0 for dogs\n",
        "\n",
        "    train_images.append(img)\n",
        "    train_labels.append(label)\n",
        "\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n",
        "\n",
        "combined = list(zip(train_images, train_labels))\n",
        "random.shuffle(combined)\n",
        "\n",
        "subset_size = int(0.5 * len(combined))\n",
        "subset = combined[:subset_size]\n",
        "\n",
        "train_images, train_labels = zip(*subset)\n",
        "train_images = np.array(train_images)\n",
        "train_labels = np.array(train_labels)\n"
      ],
      "metadata": {
        "id": "7ezWenYxIdrb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split the Training Data into Train and Validation Sets"
      ],
      "metadata": {
        "id": "iWpoJtYkJktE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the subset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GpOMpGVFIoSx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Scaling"
      ],
      "metadata": {
        "id": "cJzPbcibJmpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "mVlFTRkDOU_u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train the SVM Model"
      ],
      "metadata": {
        "id": "TxXCmBWBJwt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "62fYWnnZOXwq",
        "outputId": "bf492854-7ff1-48ba-87a2-cd4fb22dc76d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validate the Model"
      ],
      "metadata": {
        "id": "d7zaIXEWJ1TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = svm.predict(X_val)\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
        "print(classification_report(y_val, y_pred, target_names=['Cat', 'Dog']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJS7JRYSOeFQ",
        "outputId": "dfee94cc-7ebc-4b23-dad0-ee069f8caf0e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.5580\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         Cat       0.56      0.53      0.54      1244\n",
            "         Dog       0.56      0.59      0.57      1256\n",
            "\n",
            "    accuracy                           0.56      2500\n",
            "   macro avg       0.56      0.56      0.56      2500\n",
            "weighted avg       0.56      0.56      0.56      2500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to the test dataset\n",
        "test_path = '/content/drive/MyDrive/Prodigy_3/test1'\n",
        "\n",
        "# Initialize list for test images\n",
        "test_images = []\n",
        "image_names = []\n",
        "\n",
        "# Load and preprocess test images\n",
        "for filename in os.listdir(test_path):\n",
        "    img_path = os.path.join(test_path, filename)\n",
        "    img = cv2.imread(img_path)\n",
        "    img = cv2.resize(img, (64, 64))  # Resize images to 64x64\n",
        "\n",
        "    # Flatten the image to convert to a 1D array\n",
        "    img = img.flatten()\n",
        "\n",
        "    test_images.append(img)\n",
        "    image_names.append(filename)\n",
        "\n",
        "test_images = np.array(test_images)\n"
      ],
      "metadata": {
        "id": "xmxBStkdaj9X"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the same scaling to the test data\n",
        "test_images = scaler.transform(test_images)"
      ],
      "metadata": {
        "id": "q6i0zFjaaq3X"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = svm.predict(test_images)"
      ],
      "metadata": {
        "id": "zmr1_BasarsQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'Filename': image_names,\n",
        "    'Prediction': test_predictions\n",
        "})\n",
        "submission_df['Prediction'] = submission_df['Prediction'].map({0: 'Cat', 1: 'Dog'})\n",
        "submission_path = '/content/drive/MyDrive/submission.csv'\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "\n",
        "print(f\"Submission saved to {submission_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZAqph5-avi7",
        "outputId": "ba625a15-35c5-454f-bdfc-87d0bfef0c0e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission saved to /content/drive/MyDrive/submission.csv\n"
          ]
        }
      ]
    }
  ]
}